{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# CAN\u30c7\u30fc\u30bfGPU\u51e6\u7406\u30d9\u30f3\u30c1\u30de\u30fc\u30af\n",
    "\n",
    "CAN\u30d0\u30a4\u30ca\u30ea\u30c7\u30fc\u30bf\u306eGPU\u51e6\u7406\u3068CPU\u51e6\u7406\u306e\u6bd4\u8f03\u3001\u304a\u3088\u3073Parquet\u51fa\u529b\u306e\u691c\u8a3c\u3092\u884c\u3044\u307e\u3059\u3002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. \u74b0\u5883\u8a2d\u5b9a\u3068\u30a4\u30f3\u30dd\u30fc\u30c8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w4lc1zmswp",
   "metadata": {},
   "source": [
    "## 2. \u30d9\u30f3\u30c1\u30de\u30fc\u30af\u7528\u30c7\u30fc\u30bf\u751f\u6210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import decoders\n",
    "#from gpu_can_decoder import GPUCANDecoder\n",
    "from gpu_can_decoder_optimized import OptimizedGPUCANDecoder\n",
    "from cpu_can_decoder import CPUCANDecoder\n",
    "\n",
    "print(\"\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\u5b8c\u4e86\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e78b41-1928-4609-bb85-bf07709711b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u30c6\u30b9\u30c8\u7528\u30c7\u30fc\u30bf\u306e\u751f\u6210 - 1,000,000\u30e1\u30c3\u30bb\u30fc\u30b8\u4ee5\u4e0a\u306e\u307f\n",
    "test_sizes = [\n",
    "    1_000_000,     # 1M\n",
    "    5_000_000,     # 5M\n",
    "    10_000_000,    # 10M\n",
    "]\n",
    "print(\"\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u30b5\u30a4\u30ba:\", test_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "g1m07ukoahs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_can_data(n_messages):\n",
    "    \"\"\"\u5408\u6210CAN\u30c7\u30fc\u30bf\u306e\u751f\u6210\uff08OpenPilot DBC\u30d5\u30a1\u30a4\u30eb\u306b\u6e96\u62e0\uff09\"\"\"\n",
    "    # \u30ea\u30a2\u30eb\u306aCAN\u30c7\u30fc\u30bf\u5206\u5e03\u3092\u6a21\u5023\n",
    "    address_distribution = {\n",
    "        170: 0.037,  # 4\u8f2a\u901f\u5ea6\n",
    "        37: 0.037,   # \u30b9\u30c6\u30a2\u30ea\u30f3\u30b0\n",
    "        36: 0.037,\n",
    "        740: 0.044,\n",
    "        608: 0.022,\n",
    "        180: 0.018,\n",
    "    }\n",
    "    \n",
    "    # \u30a2\u30c9\u30ec\u30b9\u3092\u751f\u6210\n",
    "    addresses = []\n",
    "    for addr, prob in address_distribution.items():\n",
    "        count = int(n_messages * prob)\n",
    "        addresses.extend([addr] * count)\n",
    "    \n",
    "    # \u6b8b\u308a\u306f\u30e9\u30f3\u30c0\u30e0\u306a\u30a2\u30c9\u30ec\u30b9\n",
    "    remaining = n_messages - len(addresses)\n",
    "    other_addresses = np.random.choice([452, 466, 467, 705, 321, 562], remaining)\n",
    "    addresses.extend(other_addresses)\n",
    "    \n",
    "    # \u30b7\u30e3\u30c3\u30d5\u30eb\n",
    "    np.random.shuffle(addresses)\n",
    "    addresses = np.array(addresses[:n_messages], dtype=np.int64)\n",
    "    \n",
    "    # \u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\uff08\u5b9f\u30c7\u30fc\u30bf\u3068\u540c\u3058\u7bc4\u56f2\uff09\n",
    "    timestamps = np.linspace(46408.0, 46468.0, n_messages)\n",
    "    \n",
    "    # \u30c7\u30fc\u30bf\u30d0\u30a4\u30c8\n",
    "    data_bytes = np.zeros((n_messages, 8), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(n_messages):\n",
    "        if addresses[i] == 170:  # 4\u8f2a\u901f\u5ea6\n",
    "            # OpenPilot DBC: (0.01,-67.67) \"kph\" for Toyota RAV4\n",
    "            for j in range(4):\n",
    "                speed_kmh = np.random.uniform(55, 65)  # 55-65 km/h\n",
    "                raw_value = int((speed_kmh + 67.67) / 0.01)\n",
    "                data_bytes[i, j*2] = (raw_value >> 8) & 0xFF\n",
    "                data_bytes[i, j*2 + 1] = raw_value & 0xFF\n",
    "        elif addresses[i] == 37:  # \u30b9\u30c6\u30a2\u30ea\u30f3\u30b0\n",
    "            # \u56fa\u5b9a\u5024\u30d1\u30bf\u30fc\u30f3\uff08\u5b9f\u30c7\u30fc\u30bf\u3068\u540c\u3058\uff09\n",
    "            data_bytes[i] = [0x00, 0x00, 0x10, 0x00, 0xC0, 0x00, 0x00, 0xFD]\n",
    "        else:\n",
    "            # \u305d\u306e\u4ed6\u306f\u30e9\u30f3\u30c0\u30e0\n",
    "            data_bytes[i] = np.random.randint(0, 256, 8, dtype=np.uint8)\n",
    "    \n",
    "    return timestamps, addresses, data_bytes"
   ]
  },
  {
   "cell_type": "code",
   "id": "l13gczoc7nf",
   "source": "# \u30c7\u30b3\u30fc\u30c0\u30fc\u306e\u521d\u671f\u5316\u3068\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\uff08\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u524d\u306b\u5b9f\u884c\u5fc5\u9808\uff09\nprint(\"=== \u30c7\u30b3\u30fc\u30c0\u30fc\u306e\u521d\u671f\u5316 ===\")\noptimized_gpu_decoder = OptimizedGPUCANDecoder(batch_size=500_000, chunk_size=1)\ncpu_decoder = CPUCANDecoder(batch_size=100_000)\nprint(\"\u30c7\u30b3\u30fc\u30c0\u30fc\u521d\u671f\u5316\u5b8c\u4e86\")\n\n# CUDA\u30ab\u30fc\u30cd\u30eb\u306e\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\nprint(\"\\n=== CUDA\u30ab\u30fc\u30cd\u30eb\u306e\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7 ===\")\nwarmup_data = generate_synthetic_can_data(10_000)\nfor i in range(2):\n    print(f\"\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u5b9f\u884c {i+1}/2...\")\n    _ = optimized_gpu_decoder.decode_batch_for_benchmark(*warmup_data)\nprint(\"\u30a6\u30a9\u30fc\u30e0\u30a2\u30c3\u30d7\u5b8c\u4e86\uff01\\n\")",
   "metadata": {},
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u30d9\u30f3\u30c1\u30de\u30fc\u30af\u7d50\u679c\u683c\u7d0d\n",
    "benchmark_results = []\n",
    "\n",
    "for n_messages in test_sizes:\n",
    "    print(f\"\\n--- {n_messages:,} \u30e1\u30c3\u30bb\u30fc\u30b8\u306e\u51e6\u7406 ---\")\n",
    "    \n",
    "    # \u30c7\u30fc\u30bf\u751f\u6210\n",
    "    timestamps, addresses, data_bytes = generate_synthetic_can_data(n_messages)\n",
    "    data_size_mb = (timestamps.nbytes + addresses.nbytes + data_bytes.nbytes) / (1024**2)\n",
    "    \n",
    "    # \u62bd\u51fa\u5bfe\u8c61\u30c7\u30fc\u30bf\u30b5\u30a4\u30ba\u306e\u8a08\u7b97\uff08\u30a2\u30c9\u30ec\u30b9170\u306837\u306e\u307f\uff09\n",
    "    target_mask = (addresses == 170) | (addresses == 37)\n",
    "    target_count = np.sum(target_mask)\n",
    "    target_size_mb = (timestamps[target_mask].nbytes + addresses[target_mask].nbytes + data_bytes[target_mask].nbytes) / (1024**2)\n",
    "    \n",
    "    print(f\"\u5168\u30c7\u30fc\u30bf\u30b5\u30a4\u30ba: {data_size_mb:.1f} MB\uff08\u5185\u62bd\u51fa\u5bfe\u8c61\u30c7\u30fc\u30bf\u30b5\u30a4\u30ba: {target_size_mb:.1f} MB\uff09\")\n",
    "    \n",
    "    # GPU\u51e6\u7406\uff08\u6700\u9069\u5316\uff09\n",
    "    opt_gpu_start = time.time()\n",
    "    opt_gpu_chunk_results = optimized_gpu_decoder.decode_batch_for_benchmark(timestamps, addresses, data_bytes)\n",
    "    opt_gpu_time = time.time() - opt_gpu_start\n",
    "    \n",
    "    # CPU\u51e6\u7406\uff08\u5168\u3066\u306e\u30b5\u30a4\u30ba\u3067\u5b9f\u6e2c\uff09\n",
    "    cpu_start = time.time()\n",
    "    cpu_results = cpu_decoder.decode_batch(timestamps, addresses, data_bytes, debug_timing=True)\n",
    "    cpu_time = time.time() - cpu_start\n",
    "    \n",
    "    # CPU\u51e6\u7406\u306e\u8a73\u7d30\u6642\u9593\u3092\u8868\u793a\uff083\u3064\u306e\u4e3b\u8981\u30b9\u30c6\u30c3\u30d7\u306b\u96c6\u7d04\uff09\n",
    "    if '_timing' in cpu_results:\n",
    "        timing = cpu_results['_timing']\n",
    "        # \u30de\u30b9\u30af\u4f5c\u6210\n",
    "        mask_time = timing.get('mask_creation', 0)\n",
    "        # \u30c7\u30fc\u30bf\u62bd\u51fa\uff08\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u691c\u7d22\u3068\u914d\u5217\u5272\u308a\u5f53\u3066\uff09\n",
    "        data_extract_time = timing.get('index_search', 0) + timing.get('array_allocation', 0)\n",
    "        # \u7269\u7406\u5024\u5909\u63db\uff08\u30c7\u30b3\u30fc\u30c9\u30eb\u30fc\u30d7\u3001DataFrame\u4f5c\u6210\u3001\u30bd\u30fc\u30c8\uff09\n",
    "        physical_convert_time = (timing.get('decode_loop', 0) + \n",
    "                               timing.get('wheel_df_creation', 0) + \n",
    "                               timing.get('wheel_sort', 0))\n",
    "        \n",
    "        print(f\"\\n  === CPU\u51e6\u7406\u306e\u8a73\u7d30 ===\")\n",
    "        print(f\"  \u30de\u30b9\u30af\u4f5c\u6210: {mask_time:.4f}\u79d2\")\n",
    "        print(f\"  \u30c7\u30fc\u30bf\u62bd\u51fa: {data_extract_time:.4f}\u79d2\")\n",
    "        print(f\"  \u7269\u7406\u5024\u5909\u63db: {physical_convert_time:.4f}\u79d2\")\n",
    "        print(f\"  \u7dcf\u51e6\u7406\u6642\u9593: {cpu_time:.4f}\u79d2\")\n",
    "    \n",
    "    # \u7d50\u679c\u8a18\u9332\n",
    "    result = {\n",
    "        'n_messages': n_messages,\n",
    "        'data_size_mb': data_size_mb,\n",
    "        'opt_gpu_time': opt_gpu_time,\n",
    "        'cpu_time': cpu_time,\n",
    "        'speedup': cpu_time / opt_gpu_time,\n",
    "        'opt_gpu_throughput': n_messages / opt_gpu_time / 1e6,\n",
    "        'cpu_throughput': n_messages / cpu_time / 1e6\n",
    "    }\n",
    "    benchmark_results.append(result)\n",
    "    \n",
    "    print(f\"\\nGPU\u51e6\u7406\u6642\u9593: {opt_gpu_time:.4f}\u79d2 ({result['opt_gpu_throughput']:.1f} Mmsg/s)\")\n",
    "    print(f\"CPU\u51e6\u7406\u6642\u9593: {cpu_time:.4f}\u79d2 ({result['cpu_throughput']:.1f} Mmsg/s)\")\n",
    "    print(f\"\u9ad8\u901f\u5316\u7387: {result['speedup']:.1f}x\")\n",
    "\n",
    "# DataFrame\u306b\u5909\u63db\n",
    "benchmark_df = pd.DataFrame(benchmark_results)\n",
    "benchmark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g5lqenahs6",
   "metadata": {},
   "source": [
    "## 4. \u901f\u5ea6\u6bd4\u8f03\u306e\u53ef\u8996\u5316"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. \u901f\u5ea6\u6bd4\u8f03\u306e\u53ef\u8996\u5316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. \u307e\u3068\u3081"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u4an7vo6n5k",
   "metadata": {},
   "source": [
    "## 5. \u5b9f\u30c7\u30fc\u30bf\u3067\u306eGPU/CPU\u51e6\u7406\u3068Parquet\u51fa\u529b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acwlqppwef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u5b9f\u30c7\u30fc\u30bf\u30d1\u30b9\n",
    "input_path = \"Example_1/b0c9d2329ad1606b|2018-08-02--08-34-47/40/processed_log/CAN/raw_can\"\n",
    "\n",
    "# GPU\u51e6\u7406\uff08\u6700\u9069\u5316\uff09\n",
    "print(\"=== GPU\u51e6\u7406\uff08\u6700\u9069\u5316\uff09 ===\")\n",
    "opt_gpu_start = time.time()\n",
    "optimized_gpu_decoder.process_and_save(input_path, \"gpu_optimized_output\")\n",
    "opt_gpu_total_time = time.time() - opt_gpu_start\n",
    "print(f\"\\nGPU\u7dcf\u51e6\u7406\u6642\u9593\uff08\u6700\u9069\u5316\uff09: {opt_gpu_total_time:.3f}\u79d2\\n\")\n",
    "\n",
    "# CPU\u51e6\u7406\n",
    "print(\"\\n=== CPU\u51e6\u7406 ===\")\n",
    "cpu_start = time.time()\n",
    "cpu_decoder.process_and_save(input_path, \"cpu_output\")\n",
    "cpu_total_time = time.time() - cpu_start\n",
    "print(f\"\\nCPU\u7dcf\u51e6\u7406\u6642\u9593: {cpu_total_time:.3f}\u79d2\")\n",
    "\n",
    "print(f\"\\n\u5b9f\u30c7\u30fc\u30bf\u3067\u306e\u9ad8\u901f\u5316\u7387\uff08\u6700\u9069\u5316GPU\uff09: {cpu_total_time/opt_gpu_total_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dl1xlmfopv",
   "metadata": {},
   "source": [
    "## 6. \u51fa\u529b\u7d50\u679c\u306e\u53ef\u8996\u5316\u3068\u691c\u8a3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8rjqpl23r7u",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\u51fa\u529b\u306e\u8aad\u307f\u8fbc\u307f\n",
    "gpu_vehicle_speed = pd.read_parquet(\"gpu_optimized_output/vehicle_speed.parquet\")\n",
    "gpu_wheel_speeds = pd.read_parquet(\"gpu_optimized_output/wheel_speeds.parquet\")\n",
    "gpu_steering = pd.read_parquet(\"gpu_optimized_output/steering.parquet\")\n",
    "\n",
    "# CPU\u51fa\u529b\u306e\u8aad\u307f\u8fbc\u307f\n",
    "cpu_vehicle_speed = pd.read_parquet(\"cpu_output/vehicle_speed_cpu.parquet\")\n",
    "cpu_wheel_speeds = pd.read_parquet(\"cpu_output/wheel_speeds_cpu.parquet\")\n",
    "cpu_steering = pd.read_parquet(\"cpu_output/steering_cpu.parquet\")\n",
    "\n",
    "print(\"=== \u51fa\u529b\u30c7\u30fc\u30bf\u30b5\u30a4\u30ba ===\")\n",
    "print(f\"GPU\u51fa\u529b: {len(gpu_vehicle_speed)} \u884c\")\n",
    "print(f\"CPU\u51fa\u529b: {len(cpu_vehicle_speed)} \u884c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "btqonbm05st",
   "metadata": {},
   "source": [
    "### 6.1 GPU/CPU\u30c7\u30fc\u30bf\u306e\u4e00\u81f4\u78ba\u8a8d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "iksvgyjk0ml",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU/CPU\u30c7\u30fc\u30bf\u306e\u5148\u982d20\u4ef6\u3092\u6bd4\u8f03\n",
    "print(\"=== GPU/CPU\u30c7\u30fc\u30bf\u306e\u4e00\u81f4\u78ba\u8a8d ===\")\n",
    "print(f\"\\nGPU\u8eca\u4e21\u901f\u5ea6\u30c7\u30fc\u30bf: {len(gpu_vehicle_speed)} \u884c\")\n",
    "print(f\"CPU\u8eca\u4e21\u901f\u5ea6\u30c7\u30fc\u30bf: {len(cpu_vehicle_speed)} \u884c\")\n",
    "\n",
    "# \u30c7\u30fc\u30bf\u6570\u304c\u540c\u3058\u304b\u78ba\u8a8d\n",
    "if len(gpu_vehicle_speed) != len(cpu_vehicle_speed):\n",
    "    print(f\"\\n\u26a0\ufe0f \u8b66\u544a: \u30c7\u30fc\u30bf\u6570\u304c\u4e00\u81f4\u3057\u307e\u305b\u3093\uff01 GPU: {len(gpu_vehicle_speed)}, CPU: {len(cpu_vehicle_speed)}\")\n",
    "\n",
    "# \u5148\u982d20\u4ef6\u3092\u8868\u793a\n",
    "print(\"\\n--- GPU\u8eca\u4e21\u901f\u5ea6\u30c7\u30fc\u30bf\uff08\u5148\u982d20\u4ef6\uff09---\")\n",
    "print(gpu_vehicle_speed.head(20))\n",
    "\n",
    "print(\"\\n--- CPU\u8eca\u4e21\u901f\u5ea6\u30c7\u30fc\u30bf\uff08\u5148\u982d20\u4ef6\uff09---\") \n",
    "print(cpu_vehicle_speed.head(20))\n",
    "\n",
    "# \u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u306e\u7bc4\u56f2\u3092\u78ba\u8a8d\n",
    "print(f\"\\n--- \u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u306e\u7bc4\u56f2 ---\")\n",
    "print(f\"GPU: {gpu_vehicle_speed['timestamp'].min():.6f} ~ {gpu_vehicle_speed['timestamp'].max():.6f}\")\n",
    "print(f\"CPU: {cpu_vehicle_speed['timestamp'].min():.6f} ~ {cpu_vehicle_speed['timestamp'].max():.6f}\")\n",
    "\n",
    "# \u30bd\u30fc\u30c8\u9806\u3092\u78ba\u8a8d\n",
    "gpu_sorted = gpu_vehicle_speed['timestamp'].is_monotonic_increasing\n",
    "cpu_sorted = cpu_vehicle_speed['timestamp'].is_monotonic_increasing\n",
    "print(f\"\\n--- \u30bd\u30fc\u30c8\u72b6\u614b ---\")\n",
    "print(f\"GPU timestamp\u6607\u9806\u30bd\u30fc\u30c8: {gpu_sorted}\")\n",
    "print(f\"CPU timestamp\u6607\u9806\u30bd\u30fc\u30c8: {cpu_sorted}\")\n",
    "\n",
    "# \u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u304c\u5b8c\u5168\u4e00\u81f4\u3059\u308b\u304b\u78ba\u8a8d\n",
    "print(\"\\n--- \u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u306e\u4e00\u81f4\u78ba\u8a8d ---\")\n",
    "if len(gpu_vehicle_speed) == len(cpu_vehicle_speed):\n",
    "    timestamp_match = (gpu_vehicle_speed['timestamp'].values == cpu_vehicle_speed['timestamp'].values).all()\n",
    "    print(f\"\u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u5b8c\u5168\u4e00\u81f4: {timestamp_match}\")\n",
    "    \n",
    "    if not timestamp_match:\n",
    "        # \u6700\u521d\u306b\u4e0d\u4e00\u81f4\u304c\u898b\u3064\u304b\u3063\u305f\u7b87\u6240\u3092\u8868\u793a\n",
    "        for i in range(min(len(gpu_vehicle_speed), 100)):  # \u6700\u521d\u306e100\u4ef6\u3092\u30c1\u30a7\u30c3\u30af\n",
    "            if gpu_vehicle_speed['timestamp'].iloc[i] != cpu_vehicle_speed['timestamp'].iloc[i]:\n",
    "                print(f\"\\n\u6700\u521d\u306e\u4e0d\u4e00\u81f4\u7b87\u6240\uff08index {i}\uff09:\")\n",
    "                print(f\"  GPU: {gpu_vehicle_speed['timestamp'].iloc[i]}\")\n",
    "                print(f\"  CPU: {cpu_vehicle_speed['timestamp'].iloc[i]}\")\n",
    "                break\n",
    "\n",
    "# 4\u8f2a\u901f\u5ea6\u30c7\u30fc\u30bf\u3082\u78ba\u8a8d\n",
    "print(\"\\n\\n=== 4\u8f2a\u901f\u5ea6\u30c7\u30fc\u30bf\u306e\u78ba\u8a8d ===\")\n",
    "print(f\"GPU 4\u8f2a\u901f\u5ea6\u30c7\u30fc\u30bf: {len(gpu_wheel_speeds)} \u884c\")\n",
    "print(f\"CPU 4\u8f2a\u901f\u5ea6\u30c7\u30fc\u30bf: {len(cpu_wheel_speeds)} \u884c\")\n",
    "\n",
    "# 4\u8f2a\u901f\u5ea6\u306e\u5148\u982d5\u4ef6\u306e\u307f\u8868\u793a\n",
    "print(\"\\n--- GPU 4\u8f2a\u901f\u5ea6\u30c7\u30fc\u30bf\uff08\u5148\u982d5\u4ef6\uff09---\")\n",
    "print(gpu_wheel_speeds.head(5))\n",
    "\n",
    "print(\"\\n--- CPU 4\u8f2a\u901f\u5ea6\u30c7\u30fc\u30bf\uff08\u5148\u982d5\u4ef6\uff09---\")\n",
    "print(cpu_wheel_speeds.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0l8886vy699i",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of speed data - Combined view\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Vehicle speed time series - Both on same plot with transparency\n",
    "axes[0, 0].plot(gpu_vehicle_speed['timestamp'], gpu_vehicle_speed['speed'], \n",
    "                label='GPU Output', alpha=0.7, linewidth=2, color='blue')\n",
    "axes[0, 0].plot(cpu_vehicle_speed['timestamp'], cpu_vehicle_speed['speed'], \n",
    "                label='CPU Output', alpha=0.7, linewidth=2, color='red', linestyle='--')\n",
    "axes[0, 0].set_xlabel('Timestamp')\n",
    "axes[0, 0].set_ylabel('Speed (m/s)')\n",
    "axes[0, 0].set_title('Vehicle Speed Time Series Data (Overlapped)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Speed distribution histogram\n",
    "axes[0, 1].hist(gpu_vehicle_speed['speed'], bins=50, alpha=0.5, label='GPU', density=True)\n",
    "axes[0, 1].hist(cpu_vehicle_speed['speed'], bins=50, alpha=0.5, label='CPU', density=True)\n",
    "axes[0, 1].set_xlabel('Speed (m/s)')\n",
    "axes[0, 1].set_ylabel('Density')\n",
    "axes[0, 1].set_title('Speed Distribution Comparison')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 4-wheel speed comparison (first 1000 points)\n",
    "n_points = 1000\n",
    "axes[1, 0].plot(gpu_wheel_speeds['timestamp'][:n_points], \n",
    "                gpu_wheel_speeds['front_left'][:n_points], \n",
    "                label='Front Left', alpha=0.7)\n",
    "axes[1, 0].plot(gpu_wheel_speeds['timestamp'][:n_points], \n",
    "                gpu_wheel_speeds['front_right'][:n_points], \n",
    "                label='Front Right', alpha=0.7)\n",
    "axes[1, 0].plot(gpu_wheel_speeds['timestamp'][:n_points], \n",
    "                gpu_wheel_speeds['rear_left'][:n_points], \n",
    "                label='Rear Left', alpha=0.7)\n",
    "axes[1, 0].plot(gpu_wheel_speeds['timestamp'][:n_points], \n",
    "                gpu_wheel_speeds['rear_right'][:n_points], \n",
    "                label='Rear Right', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Timestamp')\n",
    "axes[1, 0].set_ylabel('Speed (m/s)')\n",
    "axes[1, 0].set_title('Individual Wheel Speeds (GPU Output)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# GPU vs CPU speed value scatter plot\n",
    "# Merge on timestamp\n",
    "merged = pd.merge(gpu_vehicle_speed, cpu_vehicle_speed, \n",
    "                  on='timestamp', suffixes=('_gpu', '_cpu'))\n",
    "axes[1, 1].scatter(merged['speed_cpu'], merged['speed_gpu'], alpha=0.5, s=1)\n",
    "axes[1, 1].plot([0, 20], [0, 20], 'r--', label='y=x')\n",
    "axes[1, 1].set_xlabel('CPU Speed (m/s)')\n",
    "axes[1, 1].set_ylabel('GPU Speed (m/s)')\n",
    "axes[1, 1].set_title('GPU vs CPU Speed Value Comparison')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "oa0rb3lvs6s",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u7d71\u8a08\u60c5\u5831\u306e\u6bd4\u8f03\n",
    "print(\"=== \u901f\u5ea6\u30c7\u30fc\u30bf\u306e\u7d71\u8a08\u60c5\u5831 ===\")\n",
    "print(\"\\nGPU\u51fa\u529b:\")\n",
    "print(gpu_vehicle_speed['speed'].describe())\n",
    "print(\"\\nCPU\u51fa\u529b:\")\n",
    "print(cpu_vehicle_speed['speed'].describe())\n",
    "\n",
    "# \u5dee\u5206\u5206\u6790\n",
    "if len(merged) > 0:\n",
    "    diff = merged['speed_gpu'] - merged['speed_cpu']\n",
    "    print(\"\\n=== CPU vs GPU \u5dee\u5206\u5206\u6790 ===\")\n",
    "    print(f\"\u5e73\u5747\u5dee\u5206: {diff.mean():.9f} m/s\")\n",
    "    print(f\"\u6700\u5927\u5dee\u5206: {diff.abs().max():.9f} m/s\")\n",
    "    print(f\"\u6a19\u6e96\u504f\u5dee: {diff.std():.9f} m/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qptqmbw6vuj",
   "metadata": {},
   "source": [
    "## 7. GPU/CPU\u7d50\u679c\u306e\u8a73\u7d30\u6bd4\u8f03\n",
    "\n",
    "GPU\u51e6\u7406\u304cCPU\u51e6\u7406\u3068\u540c\u3058\u7d50\u679c\u3092\u751f\u6210\u3057\u3066\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "g0lb84l6tjv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u500b\u5225\u30b0\u30e9\u30d5\u8868\u793a\uff08CPU/GPU\u5225\uff09\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# CPU Output Only\n",
    "ax1.plot(cpu_vehicle_speed['timestamp'], cpu_vehicle_speed['speed'], \n",
    "         color='red', linewidth=1.5, alpha=0.8)\n",
    "ax1.set_xlabel('Timestamp')\n",
    "ax1.set_ylabel('Speed (m/s)')\n",
    "ax1.set_title('CPU Output - Vehicle Speed Time Series', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([cpu_vehicle_speed['speed'].min() - 0.5, cpu_vehicle_speed['speed'].max() + 0.5])\n",
    "\n",
    "# GPU Output Only\n",
    "ax2.plot(gpu_vehicle_speed['timestamp'], gpu_vehicle_speed['speed'], \n",
    "         color='blue', linewidth=1.5, alpha=0.8)\n",
    "ax2.set_xlabel('Timestamp')\n",
    "ax2.set_ylabel('Speed (m/s)')\n",
    "ax2.set_title('GPU Output - Vehicle Speed Time Series', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([gpu_vehicle_speed['speed'].min() - 0.5, gpu_vehicle_speed['speed'].max() + 0.5])\n",
    "\n",
    "# Zoomed view (first 500 points) - CPU\n",
    "n_zoom = 500\n",
    "ax3.plot(cpu_vehicle_speed['timestamp'][:n_zoom], cpu_vehicle_speed['speed'][:n_zoom], \n",
    "         color='red', linewidth=2, marker='o', markersize=2, alpha=0.7)\n",
    "ax3.set_xlabel('Timestamp')\n",
    "ax3.set_ylabel('Speed (m/s)')\n",
    "ax3.set_title(f'CPU Output - Zoomed View (First {n_zoom} points)', fontsize=12)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Zoomed view (first 500 points) - GPU\n",
    "ax4.plot(gpu_vehicle_speed['timestamp'][:n_zoom], gpu_vehicle_speed['speed'][:n_zoom], \n",
    "         color='blue', linewidth=2, marker='o', markersize=2, alpha=0.7)\n",
    "ax4.set_xlabel('Timestamp')\n",
    "ax4.set_ylabel('Speed (m/s)')\n",
    "ax4.set_title(f'GPU Output - Zoomed View (First {n_zoom} points)', fontsize=12)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# \u5dee\u5206\u5206\u6790\n",
    "print(\"\\n=== CPU vs GPU \u5dee\u5206\u5206\u6790 ===\")\n",
    "if len(merged) > 0:\n",
    "    diff = merged['speed_gpu'] - merged['speed_cpu']\n",
    "    print(f\"\u30b5\u30f3\u30d7\u30eb\u6570: {len(merged):,}\")\n",
    "    print(f\"\u5e73\u5747\u5dee\u5206: {diff.mean():.9f} m/s\")\n",
    "    print(f\"\u6700\u5927\u5dee\u5206: {diff.abs().max():.9f} m/s\")\n",
    "    print(f\"\u6a19\u6e96\u504f\u5dee: {diff.std():.9f} m/s\")\n",
    "    print(f\"\u5dee\u5206\u306e\u7bc4\u56f2: [{diff.min():.9f}, {diff.max():.9f}] m/s\")\n",
    "    \n",
    "    # \u5dee\u5206\u306e\u5206\u5e03\n",
    "    print(f\"\\n\u5dee\u5206\u306e\u5206\u5e03:\")\n",
    "    print(f\"  \u5b8c\u5168\u4e00\u81f4 (\u5dee\u5206 = 0): {(diff == 0).sum():,} ({(diff == 0).sum() / len(diff) * 100:.1f}%)\")\n",
    "    print(f\"  \u5dee\u5206 < 1e-6: {(diff.abs() < 1e-6).sum():,} ({(diff.abs() < 1e-6).sum() / len(diff) * 100:.1f}%)\")\n",
    "    print(f\"  \u5dee\u5206 < 1e-3: {(diff.abs() < 1e-3).sum():,} ({(diff.abs() < 1e-3).sum() / len(diff) * 100:.1f}%)\")\n",
    "    \n",
    "    # \u5dee\u5206\u30d7\u30ed\u30c3\u30c8\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\n",
    "    \n",
    "    # \u6642\u7cfb\u5217\u5dee\u5206\n",
    "    ax1.plot(merged['timestamp'], diff, alpha=0.7, linewidth=0.5)\n",
    "    ax1.axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    ax1.set_xlabel('Timestamp')\n",
    "    ax1.set_ylabel('Speed Difference (GPU - CPU) [m/s]')\n",
    "    ax1.set_title('Speed Difference Between GPU and CPU Output Over Time')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # \u5dee\u5206\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\n",
    "    ax2.hist(diff, bins=50, alpha=0.7, color='purple', edgecolor='black')\n",
    "    ax2.set_xlabel('Speed Difference (GPU - CPU) [m/s]')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.set_title('Distribution of Speed Differences')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.axvline(x=0, color='r', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\u8b66\u544a: \u30de\u30fc\u30b8\u3055\u308c\u305f\u30c7\u30fc\u30bf\u304c\u3042\u308a\u307e\u305b\u3093\u3002\u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u304c\u4e00\u81f4\u3057\u306a\u3044\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6gu5wnxlsof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\u8f2a\u901f\u5ea6\u306e\u8a73\u7d30\u6bd4\u8f03\n",
    "print(\"\\n=== 4\u8f2a\u901f\u5ea6\u30c7\u30fc\u30bf\u306e\u6bd4\u8f03 ===\")\n",
    "\n",
    "# GPU \u3068 CPU \u306e wheel_speeds \u3092\u30de\u30fc\u30b8\n",
    "wheel_merged = pd.merge(gpu_wheel_speeds, cpu_wheel_speeds, \n",
    "                       on='timestamp', suffixes=('_gpu', '_cpu'))\n",
    "\n",
    "if len(wheel_merged) > 0:\n",
    "    wheel_names = ['front_left', 'front_right', 'rear_left', 'rear_right']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, wheel in enumerate(wheel_names):\n",
    "        # \u5dee\u5206\u8a08\u7b97\n",
    "        wheel_diff = wheel_merged[f'{wheel}_gpu'] - wheel_merged[f'{wheel}_cpu']\n",
    "        \n",
    "        # \u30d7\u30ed\u30c3\u30c8\n",
    "        axes[i].scatter(wheel_merged[f'{wheel}_cpu'], wheel_merged[f'{wheel}_gpu'], \n",
    "                       alpha=0.5, s=1, c='green')\n",
    "        axes[i].plot([0, 20], [0, 20], 'r--', linewidth=2, label='y=x (\u5b8c\u5168\u4e00\u81f4)')\n",
    "        axes[i].set_xlabel(f'CPU {wheel} (m/s)')\n",
    "        axes[i].set_ylabel(f'GPU {wheel} (m/s)')\n",
    "        axes[i].set_title(f'{wheel.replace(\"_\", \" \").title()} Wheel Speed Comparison')\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # \u7d71\u8a08\u60c5\u5831\u3092\u8868\u793a\n",
    "        text_str = f'Mean diff: {wheel_diff.mean():.6f} m/s\\n'\n",
    "        text_str += f'Max diff: {wheel_diff.abs().max():.6f} m/s\\n'\n",
    "        text_str += f'Std dev: {wheel_diff.std():.6f} m/s'\n",
    "        axes[i].text(0.05, 0.95, text_str, transform=axes[i].transAxes, \n",
    "                    verticalalignment='top', bbox=dict(boxstyle='round', \n",
    "                    facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # \u5404\u8f2a\u306e\u5dee\u5206\u7d71\u8a08\n",
    "    print(\"\\n\u5404\u8f2a\u306e\u5dee\u5206\u7d71\u8a08:\")\n",
    "    for wheel in wheel_names:\n",
    "        wheel_diff = wheel_merged[f'{wheel}_gpu'] - wheel_merged[f'{wheel}_cpu']\n",
    "        print(f\"\\n{wheel.replace('_', ' ').title()}:\")\n",
    "        print(f\"  \u5e73\u5747\u5dee\u5206: {wheel_diff.mean():.9f} m/s\")\n",
    "        print(f\"  \u6700\u5927\u5dee\u5206: {wheel_diff.abs().max():.9f} m/s\")\n",
    "        print(f\"  \u6a19\u6e96\u504f\u5dee: {wheel_diff.std():.9f} m/s\")\n",
    "        print(f\"  \u5b8c\u5168\u4e00\u81f4\u7387: {(wheel_diff == 0).sum() / len(wheel_diff) * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"\u8b66\u544a: 4\u8f2a\u901f\u5ea6\u30c7\u30fc\u30bf\u306e\u30de\u30fc\u30b8\u306b\u5931\u6557\u3057\u307e\u3057\u305f\u3002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. \u307e\u3068\u3081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u7d50\u679c\u306e\u307e\u3068\u3081\n",
    "print(\"=== CAN\u30c7\u30fc\u30bfGPU\u51e6\u7406\u306e\u6210\u679c ===\")\n",
    "print(f\"\\n1. \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9:\")\n",
    "print(f\"   - \u6700\u5927\u9ad8\u901f\u5316\u7387\uff08GPU\uff09: {benchmark_df['speedup'].max():.1f}x\")\n",
    "print(f\"   - \u6700\u5927GPU\u30b9\u30eb\u30fc\u30d7\u30c3\u30c8: {benchmark_df['opt_gpu_throughput'].max():.1f} Mmessages/sec\")\n",
    "print(f\"   - \u5e73\u5747CPU\u30b9\u30eb\u30fc\u30d7\u30c3\u30c8: {benchmark_df['cpu_throughput'].mean():.2f} Mmessages/sec\")\n",
    "\n",
    "print(f\"\\n2. \u6700\u9069\u5316\u306e\u52b9\u679c:\")\n",
    "print(f\"   - CPU\u4e8b\u524d\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0: \u5168\u30c7\u30fc\u30bf\u306e3.7%\u306e\u307f\u51e6\u7406\")\n",
    "print(f\"   - \u7121\u99c4\u306a\u51e6\u7406\u3092\u524a\u9664: NumPy\u9023\u7d50\u3001\u578b\u5909\u63db\u3001copy()\u3092\u9664\u53bb\")\n",
    "print(f\"   - \u76f4\u63a5cuDF\u4f5c\u6210: \u5fc5\u8981\u306a\u30c7\u30fc\u30bf\u306e\u307fGPU\u8ee2\u9001\")\n",
    "print(f\"   - \u30c1\u30e3\u30f3\u30af\u30b5\u30a4\u30ba\u306b\u3088\u308b\u67d4\u8edf\u6027: 1\u301c\u4e26\u5217\u6570\u307e\u3067\u8abf\u6574\u53ef\u80fd\")\n",
    "\n",
    "print(f\"\\n3. \u51fa\u529b\u5f62\u5f0f:\")\n",
    "print(f\"   - Apache Arrow\u6e96\u62e0\u306eParquet\u5f62\u5f0f\")\n",
    "print(f\"   - GPU: cuDF\u306b\u3088\u308b\u76f4\u63a5\u51fa\u529b\")\n",
    "print(f\"   - CPU: PyArrow\u306b\u3088\u308b\u51fa\u529b\")\n",
    "\n",
    "print(f\"\\n4. \u30c7\u30fc\u30bf\u54c1\u8cea:\")\n",
    "print(f\"   - \u4e21\u5b9f\u88c5\u3067\u540c\u3058\u884c\u6570\u306e\u30c7\u30fc\u30bf\u3092\u751f\u6210\")\n",
    "print(f\"   - 4\u8f2a\u901f\u5ea6\u306e\u5e73\u5747\u304b\u3089\u8eca\u4e21\u901f\u5ea6\u3092\u8a08\u7b97\")\n",
    "print(f\"   - \u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u306e\u4e00\u8cab\u6027\u3092\u4fdd\u6301\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}