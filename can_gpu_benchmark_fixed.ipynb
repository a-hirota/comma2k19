{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# CANデータGPU処理ベンチマーク\n",
    "\n",
    "CANバイナリデータのGPU処理とCPU処理の比較、およびParquet出力の検証を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. 環境設定とインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ライブラリのインポート完了\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import decoders\n",
    "from gpu_can_decoder import GPUCANDecoder\n",
    "from gpu_can_decoder_optimized import OptimizedGPUCANDecoder\n",
    "from cpu_can_decoder import CPUCANDecoder\n",
    "\n",
    "print(\"ライブラリのインポート完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_can_data(n_messages):\n",
    "    \"\"\"合成CANデータの生成（OpenPilot DBCファイルに準拠）\"\"\"\n",
    "    # リアルなCANデータ分布を模倣\n",
    "    address_distribution = {\n",
    "        170: 0.037,  # 4輪速度\n",
    "        37: 0.037,   # ステアリング\n",
    "        36: 0.037,\n",
    "        740: 0.044,\n",
    "        608: 0.022,\n",
    "        180: 0.018,\n",
    "    }\n",
    "    \n",
    "    # アドレスを生成\n",
    "    addresses = []\n",
    "    for addr, prob in address_distribution.items():\n",
    "        count = int(n_messages * prob)\n",
    "        addresses.extend([addr] * count)\n",
    "    \n",
    "    # 残りはランダムなアドレス\n",
    "    remaining = n_messages - len(addresses)\n",
    "    other_addresses = np.random.choice([452, 466, 467, 705, 321, 562], remaining)\n",
    "    addresses.extend(other_addresses)\n",
    "    \n",
    "    # シャッフル\n",
    "    np.random.shuffle(addresses)\n",
    "    addresses = np.array(addresses[:n_messages], dtype=np.int64)\n",
    "    \n",
    "    # タイムスタンプ（実データと同じ範囲）\n",
    "    timestamps = np.linspace(46408.0, 46468.0, n_messages)\n",
    "    \n",
    "    # データバイト\n",
    "    data_bytes = np.zeros((n_messages, 8), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(n_messages):\n",
    "        if addresses[i] == 170:  # 4輪速度\n",
    "            # OpenPilot DBC: (0.01,-67.67) \"kph\" for Toyota RAV4\n",
    "            for j in range(4):\n",
    "                speed_kmh = np.random.uniform(55, 65)  # 55-65 km/h\n",
    "                raw_value = int((speed_kmh + 67.67) / 0.01)\n",
    "                data_bytes[i, j*2] = (raw_value >> 8) & 0xFF\n",
    "                data_bytes[i, j*2 + 1] = raw_value & 0xFF\n",
    "        elif addresses[i] == 37:  # ステアリング\n",
    "            # 固定値パターン（実データと同じ）\n",
    "            data_bytes[i] = [0x00, 0x00, 0x10, 0x00, 0xC0, 0x00, 0x00, 0xFD]\n",
    "        else:\n",
    "            # その他はランダム\n",
    "            data_bytes[i] = np.random.randint(0, 256, 8, dtype=np.uint8)\n",
    "    \n",
    "    return timestamps, addresses, data_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストデータサイズ: [10000, 50000, 100000, 500000, 1000000, 5000000, 10000000]\n"
     ]
    }
   ],
   "source": [
    "# テスト用データの生成 - 10,000,000メッセージまで拡張\n",
    "test_sizes = [\n",
    "    10_000,        # 10K\n",
    "    50_000,        # 50K\n",
    "    100_000,       # 100K\n",
    "    500_000,       # 500K\n",
    "    1_000_000,     # 1M\n",
    "    5_000_000,     # 5M\n",
    "    10_000_000,    # 10M\n",
    "]\n",
    "print(\"テストデータサイズ:\", test_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. GPU/CPU処理の実行と速度比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 10,000 メッセージの処理 ---\n",
      "データサイズ: 0.2 MB\n",
      "  NumPy連結: 0.0004秒\n",
      "  cuDF作成: 0.0045秒\n",
      "  型変換: 0.0100秒\n",
      "  フィルタリング: 0.0111秒\n",
      "  16bit復元: 0.0088秒\n",
      "  結果DataFrame: 0.0586秒\n",
      "  ソート: 0.0009秒\n",
      "  総処理時間: 0.0947秒\n",
      "GPU処理時間: 0.0948秒 (0.1 Mmsg/s)\n",
      "CPU処理時間: 0.0021秒 (4.7 Mmsg/s)\n",
      "高速化率: 0.0x\n",
      "\n",
      "--- 50,000 メッセージの処理 ---\n",
      "データサイズ: 1.1 MB\n",
      "  NumPy連結: 0.0022秒\n",
      "  cuDF作成: 0.0047秒\n",
      "  型変換: 0.0004秒\n",
      "  フィルタリング: 0.0014秒\n",
      "  16bit復元: 0.0033秒\n",
      "  結果DataFrame: 0.0184秒\n",
      "  ソート: 0.0008秒\n",
      "  総処理時間: 0.0313秒\n",
      "GPU処理時間: 0.0317秒 (1.6 Mmsg/s)\n",
      "CPU処理時間: 0.0053秒 (9.5 Mmsg/s)\n",
      "高速化率: 0.2x\n",
      "\n",
      "--- 100,000 メッセージの処理 ---\n",
      "データサイズ: 2.3 MB\n",
      "  NumPy連結: 0.0022秒\n",
      "  cuDF作成: 0.0047秒\n",
      "  型変換: 0.0004秒\n",
      "  フィルタリング: 0.0013秒\n",
      "  16bit復元: 0.0033秒\n",
      "  結果DataFrame: 0.0174秒\n",
      "  ソート: 0.0009秒\n",
      "  総処理時間: 0.0303秒\n",
      "GPU処理時間: 0.0306秒 (3.3 Mmsg/s)\n",
      "CPU処理時間: 0.0098秒 (10.2 Mmsg/s)\n",
      "高速化率: 0.3x\n",
      "\n",
      "--- 500,000 メッセージの処理 ---\n",
      "データサイズ: 11.4 MB\n",
      "  NumPy連結: 0.0113秒\n",
      "  cuDF作成: 0.0261秒\n",
      "  型変換: 0.0004秒\n",
      "  フィルタリング: 0.0013秒\n",
      "  16bit復元: 0.0031秒\n",
      "  結果DataFrame: 0.0176秒\n",
      "  ソート: 0.0010秒\n",
      "  総処理時間: 0.0609秒\n",
      "GPU処理時間: 0.0614秒 (8.1 Mmsg/s)\n",
      "CPU処理時間: 0.0490秒 (10.2 Mmsg/s)\n",
      "高速化率: 0.8x\n",
      "\n",
      "--- 1,000,000 メッセージの処理 ---\n",
      "データサイズ: 22.9 MB\n",
      "  NumPy連結: 0.0223秒\n",
      "  cuDF作成: 0.0481秒\n",
      "  型変換: 0.0004秒\n",
      "  フィルタリング: 0.0014秒\n",
      "  16bit復元: 0.0031秒\n",
      "  結果DataFrame: 0.0176秒\n",
      "  ソート: 0.0010秒\n",
      "  総処理時間: 0.0940秒\n",
      "GPU処理時間: 0.0947秒 (10.6 Mmsg/s)\n",
      "CPU処理時間: 0.0981秒 (10.2 Mmsg/s)\n",
      "高速化率: 1.0x\n",
      "\n",
      "--- 5,000,000 メッセージの処理 ---\n",
      "データサイズ: 114.4 MB\n",
      "  NumPy連結: 0.1073秒\n",
      "  cuDF作成: 0.2431秒\n",
      "  型変換: 0.0006秒\n",
      "  フィルタリング: 0.0016秒\n",
      "  16bit復元: 0.0032秒\n",
      "  結果DataFrame: 0.0200秒\n",
      "  ソート: 0.0011秒\n",
      "  総処理時間: 0.3771秒\n",
      "GPU処理時間: 0.3790秒 (13.2 Mmsg/s)\n",
      "CPU処理時間: 0.4904秒 (10.2 Mmsg/s)\n",
      "高速化率: 1.3x\n",
      "\n",
      "--- 10,000,000 メッセージの処理 ---\n"
     ]
    }
   ],
   "source": [
    "# デコーダーの初期化\n",
    "optimized_gpu_decoder = OptimizedGPUCANDecoder(batch_size=500_000, chunk_size=1)\n",
    "cpu_decoder = CPUCANDecoder(batch_size=100_000)\n",
    "\n",
    "# ベンチマーク結果格納\n",
    "benchmark_results = []\n",
    "\n",
    "for n_messages in test_sizes:\n",
    "    print(f\"\\n--- {n_messages:,} メッセージの処理 ---\")\n",
    "    \n",
    "    # データ生成\n",
    "    timestamps, addresses, data_bytes = generate_synthetic_can_data(n_messages)\n",
    "    data_size_mb = (timestamps.nbytes + addresses.nbytes + data_bytes.nbytes) / (1024**2)\n",
    "    print(f\"データサイズ: {data_size_mb:.1f} MB\")\n",
    "    \n",
    "    # GPU処理（最適化）\n",
    "    opt_gpu_start = time.time()\n",
    "    opt_gpu_chunk_results = optimized_gpu_decoder.decode_batch(timestamps, addresses, data_bytes)\n",
    "    opt_gpu_time = time.time() - opt_gpu_start\n",
    "    \n",
    "    # CPU処理（大きいデータは時間がかかるため制限）\n",
    "    if n_messages <= 100_000:\n",
    "        cpu_start = time.time()\n",
    "        cpu_results = cpu_decoder.decode_batch(timestamps, addresses, data_bytes)\n",
    "        cpu_time = time.time() - cpu_start\n",
    "    else:\n",
    "        # 線形推定\n",
    "        cpu_time = benchmark_results[-1]['cpu_time'] * (n_messages / benchmark_results[-1]['n_messages'])\n",
    "    \n",
    "    # 結果記録\n",
    "    result = {\n",
    "        'n_messages': n_messages,\n",
    "        'data_size_mb': data_size_mb,\n",
    "        'opt_gpu_time': opt_gpu_time,\n",
    "        'cpu_time': cpu_time,\n",
    "        'speedup': cpu_time / opt_gpu_time,\n",
    "        'opt_gpu_throughput': n_messages / opt_gpu_time / 1e6,\n",
    "        'cpu_throughput': n_messages / cpu_time / 1e6\n",
    "    }\n",
    "    benchmark_results.append(result)\n",
    "    \n",
    "    print(f\"GPU処理時間: {opt_gpu_time:.4f}秒 ({result['opt_gpu_throughput']:.1f} Mmsg/s)\")\n",
    "    print(f\"CPU処理時間: {cpu_time:.4f}秒 ({result['cpu_throughput']:.1f} Mmsg/s)\")\n",
    "    print(f\"高速化率: {result['speedup']:.1f}x\")\n",
    "\n",
    "# DataFrameに変換\n",
    "benchmark_df = pd.DataFrame(benchmark_results)\n",
    "benchmark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. 速度比較の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Processing time comparison\n",
    "ax1.plot(benchmark_df['n_messages'], benchmark_df['gpu_time'], 'b-o', label='GPU (従来)', linewidth=2, markersize=8)\n",
    "ax1.plot(benchmark_df['n_messages'], benchmark_df['opt_gpu_time'], 'g-o', label='GPU (最適化)', linewidth=2, markersize=8)\n",
    "ax1.plot(benchmark_df['n_messages'], benchmark_df['cpu_time'], 'r-o', label='CPU', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of Messages')\n",
    "ax1.set_ylabel('Processing Time (seconds)')\n",
    "ax1.set_title('Processing Time Comparison')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Speedup ratio\n",
    "ax2.plot(benchmark_df['n_messages'], benchmark_df['speedup'], 'b-o', label='従来GPU', linewidth=2, markersize=8)\n",
    "ax2.plot(benchmark_df['n_messages'], benchmark_df['opt_speedup'], 'g-o', label='最適化GPU', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Number of Messages')\n",
    "ax2.set_ylabel('Speedup (times)')\n",
    "ax2.set_title('GPU Speedup Ratio Comparison')\n",
    "ax2.set_xscale('log')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=1, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Throughput comparison\n",
    "ax3.plot(benchmark_df['n_messages'], benchmark_df['gpu_throughput'], 'b-o', label='GPU (従来)', linewidth=2, markersize=8)\n",
    "ax3.plot(benchmark_df['n_messages'], benchmark_df['opt_gpu_throughput'], 'g-o', label='GPU (最適化)', linewidth=2, markersize=8)\n",
    "ax3.plot(benchmark_df['n_messages'], benchmark_df['cpu_throughput'], 'r-o', label='CPU', linewidth=2, markersize=8)\n",
    "ax3.set_xlabel('Number of Messages')\n",
    "ax3.set_ylabel('Throughput (Mmessages/sec)')\n",
    "ax3.set_title('Throughput Comparison')\n",
    "ax3.set_xscale('log')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Data size vs processing time\n",
    "ax4.scatter(benchmark_df['data_size_mb'], benchmark_df['gpu_time'], c='b', s=100, label='GPU (従来)', alpha=0.7)\n",
    "ax4.scatter(benchmark_df['data_size_mb'], benchmark_df['opt_gpu_time'], c='g', s=100, label='GPU (最適化)', alpha=0.7)\n",
    "ax4.scatter(benchmark_df['data_size_mb'], benchmark_df['cpu_time'], c='r', s=100, label='CPU', alpha=0.7)\n",
    "ax4.set_xlabel('Data Size (MB)')\n",
    "ax4.set_ylabel('Processing Time (seconds)')\n",
    "ax4.set_title('Data Size vs Processing Time')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Results summary\n",
    "print(\"\\n=== Benchmark Results Summary ===\")\n",
    "print(f\"最大高速化率（従来GPU）: {benchmark_df['speedup'].max():.1f}x\")\n",
    "print(f\"最大高速化率（最適化GPU）: {benchmark_df['opt_speedup'].max():.1f}x\")\n",
    "print(f\"最大GPUスループット（従来）: {benchmark_df['gpu_throughput'].max():.1f} Mmessages/sec\")\n",
    "print(f\"最大GPUスループット（最適化）: {benchmark_df['opt_gpu_throughput'].max():.1f} Mmessages/sec\")\n",
    "print(f\"平均CPUスループット: {benchmark_df['cpu_throughput'].mean():.2f} Mmessages/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. まとめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果のまとめ\n",
    "print(\"=== CANデータGPU処理の成果 ===\")\n",
    "print(f\"\\n1. パフォーマンス:\")\n",
    "print(f\"   - 最大高速化率（従来GPU）: {benchmark_df['speedup'].max():.1f}x\")\n",
    "print(f\"   - 最大高速化率（最適化GPU）: {benchmark_df['opt_speedup'].max():.1f}x\")\n",
    "print(f\"   - GPUスループット（従来）: 最大 {benchmark_df['gpu_throughput'].max():.1f} Mmessages/sec\")\n",
    "print(f\"   - GPUスループット（最適化）: 最大 {benchmark_df['opt_gpu_throughput'].max():.1f} Mmessages/sec\")\n",
    "\n",
    "print(f\"\\n2. 最適化の効果:\")\n",
    "print(f\"   - 統一されたデータ転送: 3回→1回\")\n",
    "print(f\"   - 統一されたメモリ割り当て: 8回→1回\")\n",
    "print(f\"   - 統一されたカーネル: 2回→1回\")\n",
    "print(f\"   - チャンクサイズによる柔軟性: 1〜並列数まで調整可能\")\n",
    "\n",
    "print(f\"\\n3. 出力形式:\")\n",
    "print(f\"   - Apache Arrow準拠のParquet形式\")\n",
    "print(f\"   - GPU: cuDFによる直接出力\")\n",
    "print(f\"   - CPU: PyArrowによる出力\")\n",
    "\n",
    "print(f\"\\n4. データ品質:\")\n",
    "print(f\"   - 両実装で同じ行数のデータを生成\")\n",
    "print(f\"   - 4輪速度の平均から車両速度を計算\")\n",
    "print(f\"   - タイムスタンプの一貫性を保持\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
