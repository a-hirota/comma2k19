{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# CANデータGPU処理ベンチマーク\n",
    "\n",
    "CANバイナリデータのGPU処理とCPU処理の比較、およびParquet出力の検証を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "## 1. 環境設定とインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import decoders\n",
    "from gpu_can_decoder import GPUCANDecoder\n",
    "from cpu_can_decoder import CPUCANDecoder\n",
    "\n",
    "print(\"ライブラリのインポート完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_can_data(n_messages):\n",
    "    \"\"\"合成CANデータの生成（OpenPilot DBCファイルに準拠）\"\"\"\n",
    "    # リアルなCANデータ分布を模倣\n",
    "    address_distribution = {\n",
    "        170: 0.037,  # 4輪速度\n",
    "        37: 0.037,   # ステアリング\n",
    "        36: 0.037,\n",
    "        740: 0.044,\n",
    "        608: 0.022,\n",
    "        180: 0.018,\n",
    "    }\n",
    "    \n",
    "    # アドレスを生成\n",
    "    addresses = []\n",
    "    for addr, prob in address_distribution.items():\n",
    "        count = int(n_messages * prob)\n",
    "        addresses.extend([addr] * count)\n",
    "    \n",
    "    # 残りはランダムなアドレス\n",
    "    remaining = n_messages - len(addresses)\n",
    "    other_addresses = np.random.choice([452, 466, 467, 705, 321, 562], remaining)\n",
    "    addresses.extend(other_addresses)\n",
    "    \n",
    "    # シャッフル\n",
    "    np.random.shuffle(addresses)\n",
    "    addresses = np.array(addresses[:n_messages], dtype=np.int64)\n",
    "    \n",
    "    # タイムスタンプ（実データと同じ範囲）\n",
    "    timestamps = np.linspace(46408.0, 46468.0, n_messages)\n",
    "    \n",
    "    # データバイト\n",
    "    data_bytes = np.zeros((n_messages, 8), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(n_messages):\n",
    "        if addresses[i] == 170:  # 4輪速度\n",
    "            # OpenPilot DBC: (0.01,-67.67) \"kph\" for Toyota RAV4\n",
    "            for j in range(4):\n",
    "                speed_kmh = np.random.uniform(55, 65)  # 55-65 km/h\n",
    "                raw_value = int((speed_kmh + 67.67) / 0.01)\n",
    "                data_bytes[i, j*2] = (raw_value >> 8) & 0xFF\n",
    "                data_bytes[i, j*2 + 1] = raw_value & 0xFF\n",
    "        elif addresses[i] == 37:  # ステアリング\n",
    "            # 固定値パターン（実データと同じ）\n",
    "            data_bytes[i] = [0x00, 0x00, 0x10, 0x00, 0xC0, 0x00, 0x00, 0xFD]\n",
    "        else:\n",
    "            # その他はランダム\n",
    "            data_bytes[i] = np.random.randint(0, 256, 8, dtype=np.uint8)\n",
    "    \n",
    "    return timestamps, addresses, data_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-sizes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用データの生成 - 10,000,000メッセージまで拡張\n",
    "test_sizes = [\n",
    "    10_000,        # 10K\n",
    "    50_000,        # 50K\n",
    "    100_000,       # 100K\n",
    "    500_000,       # 500K\n",
    "    1_000_000,     # 1M\n",
    "    5_000_000,     # 5M\n",
    "    10_000_000,    # 10M\n",
    "]\n",
    "print(\"テストデータサイズ:\", test_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1-1",
   "metadata": {},
   "source": [
    "## 1.1 生CANデータの列指向配列レイアウト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生CANデータの構造を確認\n",
    "print(\"=== 生CANデータの列指向配列レイアウト ===\\n\")\n",
    "\n",
    "# サンプルデータを生成して構造を表示\n",
    "n_sample = 5\n",
    "sample_timestamps, sample_addresses, sample_data_bytes = generate_synthetic_can_data(n_sample)\n",
    "\n",
    "print(\"生CANデータは3つの列指向配列で構成されています：\\n\")\n",
    "\n",
    "print(\"1. タイムスタンプ配列 (timestamps):\")\n",
    "print(f\"   - 型: {sample_timestamps.dtype}\")\n",
    "print(f\"   - 形状: {sample_timestamps.shape}\")\n",
    "print(f\"   - 例: {sample_timestamps}\")\n",
    "\n",
    "print(\"\\n2. アドレス配列 (addresses):\")\n",
    "print(f\"   - 型: {sample_addresses.dtype}\")\n",
    "print(f\"   - 形状: {sample_addresses.shape}\")\n",
    "print(f\"   - 例: {sample_addresses}\")\n",
    "\n",
    "print(\"\\n3. データバイト配列 (data_bytes):\")\n",
    "print(f\"   - 型: {sample_data_bytes.dtype}\")\n",
    "print(f\"   - 形状: {sample_data_bytes.shape}\")\n",
    "print(f\"   - 例:\")\n",
    "for i in range(n_sample):\n",
    "    print(f\"     メッセージ{i}: {sample_data_bytes[i]}\")\n",
    "\n",
    "print(\"\\n=== データレイアウトの特徴 ===\")\n",
    "print(\"- 列指向: 各属性（timestamp, address, data）が個別の配列として格納\")\n",
    "print(\"- 効率的: GPUでの並列処理に適した連続メモリレイアウト\")\n",
    "print(\"- Apache Arrow互換: 列指向フォーマットへの変換が容易\")\n",
    "\n",
    "# メモリレイアウトの可視化\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "# 各配列のメモリ表現\n",
    "n_messages = 10\n",
    "bar_height = 0.8\n",
    "\n",
    "# タイムスタンプ配列\n",
    "for i in range(n_messages):\n",
    "    rect = mpatches.Rectangle((i, 0), 0.9, bar_height, \n",
    "                            facecolor='lightblue', edgecolor='black', linewidth=0.5)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(i + 0.45, 0.4, f't{i}', ha='center', va='center', fontsize=8)\n",
    "\n",
    "# アドレス配列\n",
    "for i in range(n_messages):\n",
    "    rect = mpatches.Rectangle((i, 1.2), 0.9, bar_height, \n",
    "                            facecolor='lightgreen', edgecolor='black', linewidth=0.5)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(i + 0.45, 1.6, f'a{i}', ha='center', va='center', fontsize=8)\n",
    "\n",
    "# データバイト配列（2次元）\n",
    "for i in range(n_messages):\n",
    "    for j in range(8):\n",
    "        rect = mpatches.Rectangle((i, 2.4 + j * 0.1), 0.9, 0.08, \n",
    "                                facecolor='lightcoral', edgecolor='black', linewidth=0.5)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "ax.text(-1.5, 0.4, 'timestamps[]', ha='right', va='center', fontweight='bold')\n",
    "ax.text(-1.5, 1.6, 'addresses[]', ha='right', va='center', fontweight='bold')\n",
    "ax.text(-1.5, 2.8, 'data_bytes[][]', ha='right', va='center', fontweight='bold')\n",
    "\n",
    "ax.set_xlim(-2, n_messages)\n",
    "ax.set_ylim(-0.5, 3.5)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.set_title('生CANデータの列指向配列レイアウト', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# 矢印で各メッセージの関係を示す\n",
    "for i in [3, 7]:  # 例として2つのメッセージ\n",
    "    ax.annotate('', xy=(i + 0.45, 2.3), xytext=(i + 0.45, 0.9),\n",
    "                arrowprops=dict(arrowstyle='<->', color='gray', lw=0.5))\n",
    "    ax.text(i + 0.7, 1.5, f'メッセージ{i}', ha='left', va='center', fontsize=7, color='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 実際のデータサイズ計算\n",
    "print(\"\\n=== メモリ使用量の例 ===\")\n",
    "for n in [10_000, 100_000, 1_000_000, 10_000_000]:\n",
    "    timestamp_size = n * 8  # float64\n",
    "    address_size = n * 8    # int64\n",
    "    data_size = n * 8 * 1   # uint8 * 8\n",
    "    total_size = timestamp_size + address_size + data_size\n",
    "    print(f\"{n:>10,} メッセージ: {total_size / (1024**2):>8.1f} MB\")\n",
    "    print(f\"            - timestamps: {timestamp_size / (1024**2):>6.1f} MB\")\n",
    "    print(f\"            - addresses:  {address_size / (1024**2):>6.1f} MB\")\n",
    "    print(f\"            - data_bytes: {data_size / (1024**2):>6.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3",
   "metadata": {},
   "source": [
    "## 2. GPU/CPU処理の実行と速度比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# デコーダーの初期化\n",
    "gpu_decoder = GPUCANDecoder(batch_size=500_000)\n",
    "cpu_decoder = CPUCANDecoder(batch_size=100_000)\n",
    "\n",
    "# ベンチマーク結果格納\n",
    "benchmark_results = []\n",
    "\n",
    "for n_messages in test_sizes:\n",
    "    print(f\"\\n--- {n_messages:,} メッセージの処理 ---\")\n",
    "    \n",
    "    # データ生成\n",
    "    timestamps, addresses, data_bytes = generate_synthetic_can_data(n_messages)\n",
    "    data_size_mb = (timestamps.nbytes + addresses.nbytes + data_bytes.nbytes) / (1024**2)\n",
    "    print(f\"データサイズ: {data_size_mb:.1f} MB\")\n",
    "    \n",
    "    # GPU処理\n",
    "    gpu_start = time.time()\n",
    "    gpu_results = gpu_decoder.decode_batch(timestamps, addresses, data_bytes)\n",
    "    import cupy as cp\n",
    "    cp.cuda.Stream.null.synchronize()  # GPU同期\n",
    "    gpu_time = time.time() - gpu_start\n",
    "    \n",
    "    # CPU処理（大きいデータは時間がかかるため制限）\n",
    "    if n_messages <= 100_000:\n",
    "        cpu_start = time.time()\n",
    "        cpu_results = cpu_decoder.decode_batch(timestamps, addresses, data_bytes)\n",
    "        cpu_time = time.time() - cpu_start\n",
    "    else:\n",
    "        # 線形推定\n",
    "        cpu_time = benchmark_results[-1]['cpu_time'] * (n_messages / benchmark_results[-1]['n_messages'])\n",
    "    \n",
    "    # 結果記録\n",
    "    result = {\n",
    "        'n_messages': n_messages,\n",
    "        'data_size_mb': data_size_mb,\n",
    "        'gpu_time': gpu_time,\n",
    "        'cpu_time': cpu_time,\n",
    "        'speedup': cpu_time / gpu_time,\n",
    "        'gpu_throughput': n_messages / gpu_time / 1e6,\n",
    "        'cpu_throughput': n_messages / cpu_time / 1e6\n",
    "    }\n",
    "    benchmark_results.append(result)\n",
    "    \n",
    "    print(f\"GPU処理時間: {gpu_time:.4f}秒 ({result['gpu_throughput']:.1f} Mmsg/s)\")\n",
    "    print(f\"CPU処理時間: {cpu_time:.4f}秒 ({result['cpu_throughput']:.1f} Mmsg/s)\")\n",
    "    print(f\"高速化率: {result['speedup']:.1f}x\")\n",
    "\n",
    "# DataFrameに変換\n",
    "benchmark_df = pd.DataFrame(benchmark_results)\n",
    "benchmark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "## 3. 速度比較の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Processing time comparison\n",
    "ax1.plot(benchmark_df['n_messages'], benchmark_df['gpu_time'], 'b-o', label='GPU', linewidth=2, markersize=8)\n",
    "ax1.plot(benchmark_df['n_messages'], benchmark_df['cpu_time'], 'r-o', label='CPU', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of Messages')\n",
    "ax1.set_ylabel('Processing Time (seconds)')\n",
    "ax1.set_title('Processing Time Comparison')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Speedup ratio\n",
    "ax2.plot(benchmark_df['n_messages'], benchmark_df['speedup'], 'g-o', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Number of Messages')\n",
    "ax2.set_ylabel('Speedup (times)')\n",
    "ax2.set_title('GPU Speedup Ratio')\n",
    "ax2.set_xscale('log')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=1, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Throughput comparison\n",
    "ax3.plot(benchmark_df['n_messages'], benchmark_df['gpu_throughput'], 'b-o', label='GPU', linewidth=2, markersize=8)\n",
    "ax3.plot(benchmark_df['n_messages'], benchmark_df['cpu_throughput'], 'r-o', label='CPU', linewidth=2, markersize=8)\n",
    "ax3.set_xlabel('Number of Messages')\n",
    "ax3.set_ylabel('Throughput (Mmessages/sec)')\n",
    "ax3.set_title('Throughput Comparison')\n",
    "ax3.set_xscale('log')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Data size vs processing time\n",
    "ax4.scatter(benchmark_df['data_size_mb'], benchmark_df['gpu_time'], c='b', s=100, label='GPU', alpha=0.7)\n",
    "ax4.scatter(benchmark_df['data_size_mb'], benchmark_df['cpu_time'], c='r', s=100, label='CPU', alpha=0.7)\n",
    "ax4.set_xlabel('Data Size (MB)')\n",
    "ax4.set_ylabel('Processing Time (seconds)')\n",
    "ax4.set_title('Data Size vs Processing Time')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Results summary\n",
    "print(\"\\n=== Benchmark Results Summary ===\")\n",
    "print(f\"Maximum speedup: {benchmark_df['speedup'].max():.1f}x\")\n",
    "print(f\"Maximum GPU throughput: {benchmark_df['gpu_throughput'].max():.1f} Mmessages/sec\")\n",
    "print(f\"Average CPU throughput: {benchmark_df['cpu_throughput'].mean():.2f} Mmessages/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5",
   "metadata": {},
   "source": [
    "## 4. 実データでのGPU/CPU処理とParquet出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "real-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実データパス\n",
    "input_path = \"Example_1/b0c9d2329ad1606b|2018-08-02--08-34-47/40/processed_log/CAN/raw_can\"\n",
    "\n",
    "# GPU処理\n",
    "print(\"=== GPU処理 ===\")\n",
    "gpu_start = time.time()\n",
    "gpu_decoder.process_and_save(input_path, \"gpu_output\")\n",
    "gpu_total_time = time.time() - gpu_start\n",
    "print(f\"\\nGPU総処理時間: {gpu_total_time:.3f}秒\\n\")\n",
    "\n",
    "# CPU処理\n",
    "print(\"\\n=== CPU処理 ===\")\n",
    "cpu_start = time.time()\n",
    "cpu_decoder.process_and_save(input_path, \"cpu_output\")\n",
    "cpu_total_time = time.time() - cpu_start\n",
    "print(f\"\\nCPU総処理時間: {cpu_total_time:.3f}秒\")\n",
    "\n",
    "print(f\"\\n実データでの高速化率: {cpu_total_time/gpu_total_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6",
   "metadata": {},
   "source": [
    "## 5. 出力結果の可視化と検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "output-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU出力の読み込み\n",
    "gpu_vehicle_speed = pd.read_parquet(\"gpu_output/vehicle_speed.parquet\")\n",
    "gpu_wheel_speeds = pd.read_parquet(\"gpu_output/wheel_speeds.parquet\")\n",
    "gpu_steering = pd.read_parquet(\"gpu_output/steering.parquet\")\n",
    "\n",
    "# CPU出力の読み込み\n",
    "cpu_vehicle_speed = pd.read_parquet(\"cpu_output/vehicle_speed_cpu.parquet\")\n",
    "cpu_wheel_speeds = pd.read_parquet(\"cpu_output/wheel_speeds_cpu.parquet\")\n",
    "cpu_steering = pd.read_parquet(\"cpu_output/steering_cpu.parquet\")\n",
    "\n",
    "print(\"=== 出力データサイズ ===\")\n",
    "print(f\"GPU出力: {len(gpu_vehicle_speed)} 行\")\n",
    "print(f\"CPU出力: {len(cpu_vehicle_speed)} 行\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speed-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of speed data - Combined view\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Vehicle speed time series - Both on same plot with transparency\n",
    "axes[0, 0].plot(gpu_vehicle_speed['timestamp'], gpu_vehicle_speed['speed'], \n",
    "                label='GPU Output', alpha=0.7, linewidth=2, color='blue')\n",
    "axes[0, 0].plot(cpu_vehicle_speed['timestamp'], cpu_vehicle_speed['speed'], \n",
    "                label='CPU Output', alpha=0.7, linewidth=2, color='red', linestyle='--')\n",
    "axes[0, 0].set_xlabel('Timestamp')\n",
    "axes[0, 0].set_ylabel('Speed (m/s)')\n",
    "axes[0, 0].set_title('Vehicle Speed Time Series Data (Overlapped)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Speed distribution histogram\n",
    "axes[0, 1].hist(gpu_vehicle_speed['speed'], bins=50, alpha=0.5, label='GPU', density=True)\n",
    "axes[0, 1].hist(cpu_vehicle_speed['speed'], bins=50, alpha=0.5, label='CPU', density=True)\n",
    "axes[0, 1].set_xlabel('Speed (m/s)')\n",
    "axes[0, 1].set_ylabel('Density')\n",
    "axes[0, 1].set_title('Speed Distribution Comparison')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 4-wheel speed comparison (first 1000 points)\n",
    "n_points = 1000\n",
    "axes[1, 0].plot(gpu_wheel_speeds['timestamp'][:n_points], \n",
    "                gpu_wheel_speeds['front_left'][:n_points], \n",
    "                label='Front Left', alpha=0.7)\n",
    "axes[1, 0].plot(gpu_wheel_speeds['timestamp'][:n_points], \n",
    "                gpu_wheel_speeds['front_right'][:n_points], \n",
    "                label='Front Right', alpha=0.7)\n",
    "axes[1, 0].plot(gpu_wheel_speeds['timestamp'][:n_points], \n",
    "                gpu_wheel_speeds['rear_left'][:n_points], \n",
    "                label='Rear Left', alpha=0.7)\n",
    "axes[1, 0].plot(gpu_wheel_speeds['timestamp'][:n_points], \n",
    "                gpu_wheel_speeds['rear_right'][:n_points], \n",
    "                label='Rear Right', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Timestamp')\n",
    "axes[1, 0].set_ylabel('Speed (m/s)')\n",
    "axes[1, 0].set_title('Individual Wheel Speeds (GPU Output)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# GPU vs CPU speed value scatter plot\n",
    "# Merge on timestamp\n",
    "merged = pd.merge(gpu_vehicle_speed, cpu_vehicle_speed, \n",
    "                  on='timestamp', suffixes=('_gpu', '_cpu'))\n",
    "axes[1, 1].scatter(merged['speed_cpu'], merged['speed_gpu'], alpha=0.5, s=1)\n",
    "axes[1, 1].plot([0, 20], [0, 20], 'r--', label='y=x')\n",
    "axes[1, 1].set_xlabel('CPU Speed (m/s)')\n",
    "axes[1, 1].set_ylabel('GPU Speed (m/s)')\n",
    "axes[1, 1].set_title('GPU vs CPU Speed Value Comparison')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 統計情報の比較\n",
    "print(\"=== 速度データの統計情報 ===\")\n",
    "print(\"\\nGPU出力:\")\n",
    "print(gpu_vehicle_speed['speed'].describe())\n",
    "print(\"\\nCPU出力:\")\n",
    "print(cpu_vehicle_speed['speed'].describe())\n",
    "\n",
    "# 差分分析\n",
    "if len(merged) > 0:\n",
    "    diff = merged['speed_gpu'] - merged['speed_cpu']\n",
    "    print(\"\\n=== CPU vs GPU 差分分析 ===\")\n",
    "    print(f\"平均差分: {diff.mean():.9f} m/s\")\n",
    "    print(f\"最大差分: {diff.abs().max():.9f} m/s\")\n",
    "    print(f\"標準偏差: {diff.std():.9f} m/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section7",
   "metadata": {},
   "source": [
    "## 6. まとめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果のまとめ\n",
    "print(\"=== CANデータGPU処理の成果 ===\")\n",
    "print(f\"\\n1. パフォーマンス:\")\n",
    "print(f\"   - 最大高速化率: {benchmark_df['speedup'].max():.1f}x\")\n",
    "print(f\"   - GPUスループット: 最大 {benchmark_df['gpu_throughput'].max():.1f} Mmessages/sec\")\n",
    "print(f\"   - 実データ処理: GPU {gpu_total_time:.3f}秒 vs CPU {cpu_total_time:.3f}秒\")\n",
    "\n",
    "print(f\"\\n2. 出力形式:\")\n",
    "print(f\"   - Apache Arrow準拠のParquet形式\")\n",
    "print(f\"   - GPU: cuDFによる直接出力\")\n",
    "print(f\"   - CPU: PyArrowによる出力\")\n",
    "\n",
    "print(f\"\\n3. データ品質:\")\n",
    "print(f\"   - 両実装で同じ行数のデータを生成\")\n",
    "print(f\"   - 4輪速度の平均から車両速度を計算\")\n",
    "print(f\"   - タイムスタンプの一貫性を保持\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (cudf_dev)",
   "language": "python",
   "name": "cudf_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "nbformat": 4,
  "nbformat_minor": 5
 }
}