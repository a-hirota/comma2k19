{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CANデータGPU処理ベンチマーク（プロファイリング版）\n",
    "\n",
    "メモリプロファイリングとGPU使用率モニタリングを含む詳細なベンチマーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設定とプロファイリングツールのセットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import gc\n",
    "import psutil\n",
    "import rmm\n",
    "from datetime import datetime\n",
    "import threading\n",
    "from collections import deque\n",
    "\n",
    "# GPU monitoring tools\n",
    "try:\n",
    "    import pynvml\n",
    "except ImportError:\n",
    "    !pip install nvidia-ml-py3\n",
    "    import pynvml\n",
    "\n",
    "# Memory profiling\n",
    "from rmm.statistics import ProfilerRecords, statistics\n",
    "\n",
    "# Import decoders\n",
    "from gpu_can_decoder import GPUCANDecoder\n",
    "from cpu_can_decoder import CPUCANDecoder\n",
    "\n",
    "# Initialize NVML for GPU monitoring\n",
    "pynvml.nvmlInit()\n",
    "gpu_handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "# Get GPU info\n",
    "gpu_name = pynvml.nvmlDeviceGetName(gpu_handle).decode('utf-8')\n",
    "gpu_mem_info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)\n",
    "print(f\"GPU: {gpu_name}\")\n",
    "print(f\"GPU Memory: {gpu_mem_info.total / (1024**3):.1f} GB\")\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU使用率モニタリングクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPUMonitor:\n",
    "    \"\"\"GPU使用率とメモリ使用量をモニタリング\"\"\"\n",
    "    \n",
    "    def __init__(self, interval=0.1):\n",
    "        self.interval = interval\n",
    "        self.gpu_handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        self.monitoring = False\n",
    "        self.timestamps = deque(maxlen=10000)\n",
    "        self.gpu_utils = deque(maxlen=10000)\n",
    "        self.mem_utils = deque(maxlen=10000)\n",
    "        self.mem_used = deque(maxlen=10000)\n",
    "        self.thread = None\n",
    "    \n",
    "    def _monitor_loop(self):\n",
    "        \"\"\"モニタリングループ\"\"\"\n",
    "        start_time = time.time()\n",
    "        while self.monitoring:\n",
    "            current_time = time.time() - start_time\n",
    "            \n",
    "            # GPU使用率\n",
    "            util = pynvml.nvmlDeviceGetUtilizationRates(self.gpu_handle)\n",
    "            self.gpu_utils.append(util.gpu)\n",
    "            \n",
    "            # メモリ使用量\n",
    "            mem_info = pynvml.nvmlDeviceGetMemoryInfo(self.gpu_handle)\n",
    "            self.mem_utils.append(100 * mem_info.used / mem_info.total)\n",
    "            self.mem_used.append(mem_info.used / (1024**3))  # GB\n",
    "            \n",
    "            self.timestamps.append(current_time)\n",
    "            time.sleep(self.interval)\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"モニタリング開始\"\"\"\n",
    "        self.monitoring = True\n",
    "        self.thread = threading.Thread(target=self._monitor_loop)\n",
    "        self.thread.start()\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"モニタリング停止\"\"\"\n",
    "        self.monitoring = False\n",
    "        if self.thread:\n",
    "            self.thread.join()\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"データ取得\"\"\"\n",
    "        return {\n",
    "            'timestamps': list(self.timestamps),\n",
    "            'gpu_utils': list(self.gpu_utils),\n",
    "            'mem_utils': list(self.mem_utils),\n",
    "            'mem_used_gb': list(self.mem_used)\n",
    "        }\n",
    "    \n",
    "    def plot(self, title=\"GPU Monitoring Results\"):\n",
    "        \"\"\"結果のプロット\"\"\"\n",
    "        data = self.get_data()\n",
    "        if not data['timestamps']:\n",
    "            print(\"No monitoring data available\")\n",
    "            return\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "        \n",
    "        # GPU使用率\n",
    "        ax1.plot(data['timestamps'], data['gpu_utils'], 'b-', linewidth=1.5)\n",
    "        ax1.set_ylabel('GPU Utilization (%)')\n",
    "        ax1.set_ylim(0, 105)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_title(f\"{title} - GPU Utilization\")\n",
    "        \n",
    "        # メモリ使用量\n",
    "        ax2.plot(data['timestamps'], data['mem_used_gb'], 'r-', linewidth=1.5, label='Used')\n",
    "        ax2.axhline(y=24, color='k', linestyle='--', alpha=0.5, label='Total (24GB)')\n",
    "        ax2.set_xlabel('Time (seconds)')\n",
    "        ax2.set_ylabel('GPU Memory (GB)')\n",
    "        ax2.set_ylim(0, 26)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "        ax2.set_title(\"GPU Memory Usage\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 統計情報\n",
    "        print(f\"\\nGPU Utilization Statistics:\")\n",
    "        print(f\"  Average: {np.mean(data['gpu_utils']):.1f}%\")\n",
    "        print(f\"  Maximum: {np.max(data['gpu_utils']):.1f}%\")\n",
    "        print(f\"  Minimum: {np.min(data['gpu_utils']):.1f}%\")\n",
    "        \n",
    "        print(f\"\\nGPU Memory Statistics:\")\n",
    "        print(f\"  Average: {np.mean(data['mem_used_gb']):.2f} GB\")\n",
    "        print(f\"  Maximum: {np.max(data['mem_used_gb']):.2f} GB\")\n",
    "        print(f\"  Minimum: {np.min(data['mem_used_gb']):.2f} GB\")\n",
    "\n",
    "# モニターのテスト\n",
    "monitor = GPUMonitor(interval=0.05)\n",
    "print(\"GPU Monitor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RMM メモリプロファイリング設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMM statistics を有効化\n",
    "rmm.statistics.enable_statistics()\n",
    "\n",
    "# RMM を再初期化（統計機能付き）\n",
    "rmm.reinitialize(\n",
    "    managed_memory=False,  # まずは通常のGPUメモリで試す\n",
    "    pool_allocator=True,\n",
    "    initial_pool_size=2<<30,    # 2GB\n",
    "    maximum_pool_size=22<<30,   # 22GB (24GBの GPU用)\n",
    "    logging=True\n",
    ")\n",
    "\n",
    "def print_rmm_statistics():\n",
    "    \"\"\"RMM統計情報を表示\"\"\"\n",
    "    stats = rmm.statistics.get_statistics()\n",
    "    print(\"\\nRMM Memory Statistics:\")\n",
    "    print(f\"  Current allocated: {stats.current_bytes / (1024**3):.2f} GB\")\n",
    "    print(f\"  Peak allocated: {stats.peak_bytes / (1024**3):.2f} GB\")\n",
    "    print(f\"  Total allocations: {stats.n_allocations}\")\n",
    "    print(f\"  Total deallocations: {stats.n_deallocations}\")\n",
    "\n",
    "# CuPy メモリプール情報\n",
    "def print_cupy_memory_info():\n",
    "    \"\"\"CuPyメモリプール情報を表示\"\"\"\n",
    "    mempool = cp.get_default_memory_pool()\n",
    "    print(\"\\nCuPy Memory Pool:\")\n",
    "    print(f\"  Used: {mempool.used_bytes() / (1024**3):.2f} GB\")\n",
    "    print(f\"  Total: {mempool.total_bytes() / (1024**3):.2f} GB\")\n",
    "\n",
    "print(\"Memory profiling setup complete\")\n",
    "print_rmm_statistics()\n",
    "print_cupy_memory_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. プロファイリング付きデータ生成関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_can_data_profiled(n_messages):\n",
    "    \"\"\"プロファイリング付きCANデータ生成\"\"\"\n",
    "    # リアルなCANデータ分布\n",
    "    address_distribution = {\n",
    "        170: 0.037,  # 4輪速度\n",
    "        37: 0.037,   # ステアリング\n",
    "        36: 0.037,\n",
    "        740: 0.044,\n",
    "        608: 0.022,\n",
    "        180: 0.018,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nGenerating {n_messages:,} messages...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # アドレスを生成\n",
    "    addresses = []\n",
    "    for addr, prob in address_distribution.items():\n",
    "        count = int(n_messages * prob)\n",
    "        addresses.extend([addr] * count)\n",
    "    \n",
    "    # 残りはランダムなアドレス\n",
    "    remaining = n_messages - len(addresses)\n",
    "    other_addresses = np.random.choice([452, 466, 467, 705, 321, 562], remaining)\n",
    "    addresses.extend(other_addresses)\n",
    "    \n",
    "    # シャッフル\n",
    "    np.random.shuffle(addresses)\n",
    "    addresses = np.array(addresses[:n_messages], dtype=np.int64)\n",
    "    \n",
    "    # タイムスタンプ（約60秒間）\n",
    "    timestamps = np.linspace(46408.0, 46468.0, n_messages)\n",
    "    \n",
    "    # データバイト\n",
    "    data_bytes = np.zeros((n_messages, 8), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(n_messages):\n",
    "        if addresses[i] == 170:  # 4輪速度\n",
    "            for j in range(4):\n",
    "                speed_kmh = np.random.uniform(55, 65)\n",
    "                raw_value = int((speed_kmh + 67.67) / 0.01)\n",
    "                data_bytes[i, j*2] = (raw_value >> 8) & 0xFF\n",
    "                data_bytes[i, j*2 + 1] = raw_value & 0xFF\n",
    "        elif addresses[i] == 37:  # ステアリング\n",
    "            data_bytes[i] = [0x00, 0x00, 0x10, 0x00, 0xC0, 0x00, 0x00, 0xFD]\n",
    "        else:\n",
    "            data_bytes[i] = np.random.randint(0, 256, 8, dtype=np.uint8)\n",
    "    \n",
    "    gen_time = time.time() - start_time\n",
    "    data_size_mb = (timestamps.nbytes + addresses.nbytes + data_bytes.nbytes) / (1024**2)\n",
    "    \n",
    "    print(f\"  Generation time: {gen_time:.2f} seconds\")\n",
    "    print(f\"  Data size: {data_size_mb:.1f} MB\")\n",
    "    print(f\"  Throughput: {n_messages / gen_time / 1e6:.1f} Mmessages/sec\")\n",
    "    \n",
    "    return timestamps, addresses, data_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. プロファイリング付きベンチマーク実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デコーダーの初期化\n",
    "gpu_decoder = GPUCANDecoder(batch_size=1_000_000)\n",
    "cpu_decoder = CPUCANDecoder()\n",
    "\n",
    "# テストサイズ\n",
    "test_sizes = [100_000, 1_000_000, 10_000_000]\n",
    "benchmark_results = []\n",
    "\n",
    "for n_messages in test_sizes:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing with {n_messages:,} messages\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # メモリクリア\n",
    "    gc.collect()\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    \n",
    "    # 初期メモリ状態\n",
    "    print(\"\\nInitial memory state:\")\n",
    "    print_rmm_statistics()\n",
    "    print_cupy_memory_info()\n",
    "    \n",
    "    # データ生成\n",
    "    timestamps, addresses, data_bytes = generate_synthetic_can_data_profiled(n_messages)\n",
    "    \n",
    "    # GPU処理（モニタリング付き）\n",
    "    print(\"\\n--- GPU Processing ---\")\n",
    "    monitor.start()\n",
    "    \n",
    "    gpu_start = time.time()\n",
    "    with statistics.profiler(name=\"GPU_decode\"):\n",
    "        gpu_results = gpu_decoder.decode_batch(timestamps, addresses, data_bytes)\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "    gpu_time = time.time() - gpu_start\n",
    "    \n",
    "    monitor.stop()\n",
    "    \n",
    "    # GPU結果の統計\n",
    "    n_decoded_gpu = sum(len(df) for df in gpu_results.values() if df is not None)\n",
    "    \n",
    "    print(f\"\\nGPU Results:\")\n",
    "    print(f\"  Processing time: {gpu_time:.3f} seconds\")\n",
    "    print(f\"  Throughput: {n_messages / gpu_time / 1e6:.1f} Mmessages/sec\")\n",
    "    print(f\"  Decoded messages: {n_decoded_gpu:,}\")\n",
    "    \n",
    "    # メモリ状態\n",
    "    print(\"\\nPost-GPU memory state:\")\n",
    "    print_rmm_statistics()\n",
    "    print_cupy_memory_info()\n",
    "    \n",
    "    # GPU使用率のプロット\n",
    "    monitor.plot(title=f\"GPU Processing - {n_messages:,} messages\")\n",
    "    \n",
    "    # CPU処理（小さいデータセットのみ）\n",
    "    if n_messages <= 1_000_000:\n",
    "        print(\"\\n--- CPU Processing ---\")\n",
    "        cpu_start = time.time()\n",
    "        cpu_results = cpu_decoder.decode_batch(timestamps, addresses, data_bytes)\n",
    "        cpu_time = time.time() - cpu_start\n",
    "        \n",
    "        n_decoded_cpu = sum(len(df) for df in cpu_results.values() if df is not None)\n",
    "        \n",
    "        print(f\"\\nCPU Results:\")\n",
    "        print(f\"  Processing time: {cpu_time:.3f} seconds\")\n",
    "        print(f\"  Throughput: {n_messages / cpu_time / 1e6:.1f} Mmessages/sec\")\n",
    "        print(f\"  Decoded messages: {n_decoded_cpu:,}\")\n",
    "        print(f\"\\nSpeedup: {cpu_time / gpu_time:.1f}x\")\n",
    "    else:\n",
    "        cpu_time = None\n",
    "        print(\"\\nCPU processing skipped for large dataset\")\n",
    "    \n",
    "    # 結果記録\n",
    "    result = {\n",
    "        'n_messages': n_messages,\n",
    "        'gpu_time': gpu_time,\n",
    "        'cpu_time': cpu_time,\n",
    "        'speedup': cpu_time / gpu_time if cpu_time else None,\n",
    "        'gpu_throughput_mmsg': n_messages / gpu_time / 1e6,\n",
    "        'n_decoded_gpu': n_decoded_gpu,\n",
    "        'gpu_util_avg': np.mean(monitor.get_data()['gpu_utils']),\n",
    "        'gpu_util_max': np.max(monitor.get_data()['gpu_utils']),\n",
    "        'mem_used_avg_gb': np.mean(monitor.get_data()['mem_used_gb']),\n",
    "        'mem_used_max_gb': np.max(monitor.get_data()['mem_used_gb'])\n",
    "    }\n",
    "    benchmark_results.append(result)\n",
    "    \n",
    "    # クリーンアップ\n",
    "    del timestamps, addresses, data_bytes, gpu_results\n",
    "    if cpu_time:\n",
    "        del cpu_results\n",
    "    gc.collect()\n",
    "    cp.get_default_memory_pool().free_all_blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 結果の分析と可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果をDataFrameに\n",
    "benchmark_df = pd.DataFrame(benchmark_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BENCHMARK SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(benchmark_df.to_string(index=False))\n",
    "\n",
    "# パフォーマンス分析のプロット\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# GPU使用率 vs データサイズ\n",
    "ax1.plot(benchmark_df['n_messages'], benchmark_df['gpu_util_avg'], 'b-o', \n",
    "         label='Average', linewidth=2, markersize=8)\n",
    "ax1.plot(benchmark_df['n_messages'], benchmark_df['gpu_util_max'], 'r--o', \n",
    "         label='Maximum', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of Messages')\n",
    "ax1.set_ylabel('GPU Utilization (%)')\n",
    "ax1.set_title('GPU Utilization vs Data Size')\n",
    "ax1.set_xscale('log')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# メモリ使用量 vs データサイズ\n",
    "ax2.plot(benchmark_df['n_messages'], benchmark_df['mem_used_avg_gb'], 'g-o', \n",
    "         label='Average', linewidth=2, markersize=8)\n",
    "ax2.plot(benchmark_df['n_messages'], benchmark_df['mem_used_max_gb'], 'm--o', \n",
    "         label='Maximum', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Number of Messages')\n",
    "ax2.set_ylabel('GPU Memory (GB)')\n",
    "ax2.set_title('GPU Memory Usage vs Data Size')\n",
    "ax2.set_xscale('log')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# スループット vs データサイズ\n",
    "ax3.plot(benchmark_df['n_messages'], benchmark_df['gpu_throughput_mmsg'], 'c-o', \n",
    "         linewidth=2, markersize=8)\n",
    "ax3.set_xlabel('Number of Messages')\n",
    "ax3.set_ylabel('Throughput (Mmessages/sec)')\n",
    "ax3.set_title('GPU Throughput Scaling')\n",
    "ax3.set_xscale('log')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 処理時間のスケーリング\n",
    "ax4.plot(benchmark_df['n_messages'], benchmark_df['gpu_time'], 'b-o', \n",
    "         label='GPU', linewidth=2, markersize=8)\n",
    "if benchmark_df['cpu_time'].notna().any():\n",
    "    mask = benchmark_df['cpu_time'].notna()\n",
    "    ax4.plot(benchmark_df.loc[mask, 'n_messages'], \n",
    "             benchmark_df.loc[mask, 'cpu_time'], \n",
    "             'r--o', label='CPU', linewidth=2, markersize=8)\n",
    "ax4.set_xlabel('Number of Messages')\n",
    "ax4.set_ylabel('Processing Time (seconds)')\n",
    "ax4.set_title('Processing Time Scaling')\n",
    "ax4.set_xscale('log')\n",
    "ax4.set_yscale('log')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ボトルネック分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Performance Bottleneck Analysis ===\")\n",
    "\n",
    "# GPU使用率の分析\n",
    "avg_gpu_util = benchmark_df['gpu_util_avg'].mean()\n",
    "print(f\"\\n1. GPU Utilization:\")\n",
    "print(f\"   Average across all tests: {avg_gpu_util:.1f}%\")\n",
    "\n",
    "if avg_gpu_util < 50:\n",
    "    print(\"   ⚠️  Low GPU utilization detected!\")\n",
    "    print(\"   Potential causes:\")\n",
    "    print(\"   - Small batch sizes\")\n",
    "    print(\"   - CPU-GPU data transfer overhead\")\n",
    "    print(\"   - Kernel launch overhead\")\n",
    "    print(\"   Recommendations:\")\n",
    "    print(\"   - Increase batch size\")\n",
    "    print(\"   - Use pinned memory for transfers\")\n",
    "    print(\"   - Implement kernel fusion\")\n",
    "elif avg_gpu_util < 80:\n",
    "    print(\"   ⚠️  Moderate GPU utilization\")\n",
    "    print(\"   Room for optimization exists\")\n",
    "else:\n",
    "    print(\"   ✓ Good GPU utilization\")\n",
    "\n",
    "# メモリ帯域幅の推定\n",
    "print(f\"\\n2. Memory Bandwidth Analysis:\")\n",
    "for idx, row in benchmark_df.iterrows():\n",
    "    data_size_gb = (row['n_messages'] * 24) / (1024**3)\n",
    "    bandwidth_gb = data_size_gb / row['gpu_time']\n",
    "    theoretical_max = 900  # GB/s for modern GPUs\n",
    "    efficiency = (bandwidth_gb / theoretical_max) * 100\n",
    "    \n",
    "    print(f\"   {row['n_messages']:,} messages:\")\n",
    "    print(f\"     Achieved: {bandwidth_gb:.1f} GB/s\")\n",
    "    print(f\"     Efficiency: {efficiency:.1f}%\")\n",
    "\n",
    "# カーネル効率の分析\n",
    "print(f\"\\n3. Kernel Efficiency:\")\n",
    "print(f\"   Messages per kernel launch: {gpu_decoder.batch_size:,}\")\n",
    "print(f\"   Estimated kernel launches:\")\n",
    "for idx, row in benchmark_df.iterrows():\n",
    "    n_launches = (row['n_messages'] + gpu_decoder.batch_size - 1) // gpu_decoder.batch_size\n",
    "    print(f\"     {row['n_messages']:,} messages: {n_launches} launches\")\n",
    "\n",
    "# 推奨事項\n",
    "print(f\"\\n4. Optimization Recommendations:\")\n",
    "print(\"   Based on the profiling results:\")\n",
    "\n",
    "if avg_gpu_util < 50:\n",
    "    print(\"   - Priority: Increase GPU utilization\")\n",
    "    print(\"   - Consider using CUDA streams for overlap\")\n",
    "    print(\"   - Implement double buffering\")\n",
    "\n",
    "if benchmark_df['mem_used_max_gb'].max() > 20:\n",
    "    print(\"   - Memory usage is high, consider:\")\n",
    "    print(\"     - Streaming processing for large datasets\")\n",
    "    print(\"     - More aggressive memory pooling\")\n",
    "\n",
    "print(\"\\n   - General optimizations:\")\n",
    "print(\"     - Use CUDA graphs for kernel launch overhead reduction\")\n",
    "print(\"     - Implement kernel fusion for related operations\")\n",
    "print(\"     - Consider mixed precision (FP16) where applicable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 詳細なRMMプロファイリング結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMM統計の詳細表示\n",
    "print(\"=== Detailed RMM Memory Profile ===\")\n",
    "\n",
    "# プロファイラーレコードの取得\n",
    "records = statistics.get_profiler_records()\n",
    "\n",
    "if records:\n",
    "    # レコードをDataFrameに変換\n",
    "    profile_data = []\n",
    "    for record in records:\n",
    "        profile_data.append({\n",
    "            'name': record.name,\n",
    "            'num_calls': record.num_calls,\n",
    "            'total_bytes': record.total_bytes / (1024**3),  # GB\n",
    "            'peak_bytes': record.peak_bytes / (1024**3),    # GB\n",
    "            'avg_bytes': (record.total_bytes / record.num_calls / (1024**3)) if record.num_calls > 0 else 0\n",
    "        })\n",
    "    \n",
    "    profile_df = pd.DataFrame(profile_data)\n",
    "    profile_df = profile_df.sort_values('total_bytes', ascending=False)\n",
    "    \n",
    "    print(\"\\nMemory allocation by operation:\")\n",
    "    print(profile_df.to_string(index=False))\n",
    "    \n",
    "    # 可視化\n",
    "    if len(profile_df) > 0:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Total bytes by operation\n",
    "        profile_df.plot(x='name', y='total_bytes', kind='bar', ax=ax1)\n",
    "        ax1.set_ylabel('Total Memory (GB)')\n",
    "        ax1.set_title('Total Memory Allocation by Operation')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Peak bytes by operation\n",
    "        profile_df.plot(x='name', y='peak_bytes', kind='bar', ax=ax2, color='orange')\n",
    "        ax2.set_ylabel('Peak Memory (GB)')\n",
    "        ax2.set_title('Peak Memory Usage by Operation')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No profiling records available\")\n",
    "\n",
    "# 最終的なメモリ状態\n",
    "print(\"\\n=== Final Memory State ===\")\n",
    "print_rmm_statistics()\n",
    "print_cupy_memory_info()\n",
    "\n",
    "# GPU情報の最終確認\n",
    "mem_info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)\n",
    "print(f\"\\nGPU Memory (NVML):\")\n",
    "print(f\"  Total: {mem_info.total / (1024**3):.1f} GB\")\n",
    "print(f\"  Used: {mem_info.used / (1024**3):.2f} GB\")\n",
    "print(f\"  Free: {mem_info.free / (1024**3):.2f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
